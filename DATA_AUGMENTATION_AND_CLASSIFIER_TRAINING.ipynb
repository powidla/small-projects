{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSc_LTPWLOgB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.parallel\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import sklearn.metrics as metrics\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = 'g4gan_big.pkl'\n",
        "model_size = 32\n",
        "seq_len = 512\n",
        "onehot_len = 5\n",
        "hidden_state_len = 128\n",
        "g4gan = load_g4gan_generator(weights_path, model_size, seq_len,\n",
        "                             onehot_len)\n",
        "g4gan.eval()"
      ],
      "metadata": {
        "id": "tvMII7a0LSvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# G4detector\n",
        "class G4Detector(nn.Module):\n",
        "    def __init__(self, onehot_len):\n",
        "        super(G4Detector, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(onehot_len, 80, 2)\n",
        "        self.conv2 = nn.Conv1d(onehot_len, 80, 3)\n",
        "        self.conv3 = nn.Conv1d(onehot_len, 96, 6)\n",
        "        self.linear_block = nn.Sequential(nn.Linear(256, 32),\n",
        "                                          nn.ReLU(), nn.Linear(32, 1), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = x.transpose(1, 2)\n",
        "        output1 = self.conv1(output)\n",
        "        output2 = self.conv2(output)\n",
        "        output3 = self.conv3(output)\n",
        "        (output1, _) = torch.max(output1, 2)\n",
        "        (output2, _) = torch.max(output2, 2)\n",
        "        (output3, _) = torch.max(output3, 2)\n",
        "        output = torch.cat([output1, output2, output3], dim=1)\n",
        "        output = self.linear_block(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "# Data\n",
        "g4_np_data_path = 'G4_Chip_seq_quadruplex_norm.npy'\n",
        "batch_size = 128\n",
        "test_ratio = 0.1\n",
        "shuffle_train_each_epoch = True\n",
        "# 0: real data\n",
        "# 1: fake data\n",
        "# 2: real+fake data\n",
        "pos_class_strategy = 2\n",
        "# 0: random\n",
        "# 1: dishuffle\n",
        "negative_class_stratery = 0\n",
        "input = np.load(g4_np_data_path)\n",
        "if pos_class_strategy == 1 or pos_class_strategy == 2:\n",
        "    with torch.no_grad():\n",
        "        noise = torch.Tensor(input.shape[0],\n",
        "                             hidden_state_len).uniform_(-1, 1)\n",
        "        fake = g4gan(noise)\n",
        "        (values, indices_hot) = fake.max(2)\n",
        "        fake[:, :, :] = 0\n",
        "        indices_hot = indices_hot.view(indices_hot.shape[0],\n",
        "                                       indices_hot.shape[1], 1)\n",
        "        fake = fake.scatter_(2, indices_hot, 1)\n",
        "        input_fake = fake.detach().numpy()\n",
        "num_g4 = input.shape[0]\n",
        "num_test = int(np.ceil(num_g4 * test_ratio))\n",
        "num_train = num_g4 - num_test\n",
        "indices = np.arange(num_g4)\n",
        "np.random.shuffle(indices)\n",
        "train_data_indices = indices[:num_train]\n",
        "test_data_indices = indices[num_train:]\n",
        "if pos_class_strategy == 0:\n",
        "    x_train_pos = input[train_data_indices]\n",
        "elif pos_class_strategy == 1:\n",
        "    x_train_pos = input_fake[train_data_indices]\n",
        "elif pos_class_strategy == 2:\n",
        "    x_train_pos = np.concatenate((input[train_data_indices],\n",
        "                                  input_fake[train_data_indices]))\n",
        "x_test_pos = input[test_data_indices]\n",
        "y_train_pos = np.repeat(np.array([[1.]]), x_train_pos.shape[0], axis=0)\n",
        "y_test_pos = np.repeat(np.array([[1.]]), x_test_pos.shape[0], axis=0)\n",
        "codes = np.eye(5)\n",
        "x_train_neg = []\n",
        "x_test_neg = []\n",
        "if negative_class_stratery == 0:\n",
        "    for i in range(x_train_pos.shape[0]):\n",
        "        x_train_neg.append(codes[np.random.choice(codes.shape[0],\n",
        "                                                  size=x_train_pos.shape[1], p=[0.25, 0.25,\n",
        "                                                                                0.25, 0.25, 0])])\n",
        "    x_train_neg = np.array(x_train_neg)\n",
        "\n",
        "    for i in range(y_test_pos.shape[0]):\n",
        "        x_test_neg.append(codes[np.random.choice(codes.shape[0],\n",
        "                                                 size=x_test_pos.shape[1], p=[0.25, 0.25,\n",
        "                                                                              0.25, 0.25, 0])])\n",
        "    x_test_neg = np.array(x_test_neg)\n",
        "elif negative_class_stratery == 1:\n",
        "    for x_tp in x_train_pos:\n",
        "        x_train_neg.append(np.random.permutation(x_tp))\n",
        "    x_train_neg = np.array(x_train_neg)\n",
        "    for x_tp in x_test_pos:\n",
        "        x_test_neg.append(np.random.permutation(x_tp))\n",
        "    x_test_neg = np.array(x_test_neg)\n",
        "y_train_neg = np.repeat(np.array([[0.]]), x_train_neg.shape[0], axis=0)\n",
        "y_test_neg = np.repeat(np.array([[0.]]), x_test_neg.shape[0], axis=0)\n",
        "x_np_train = np.concatenate((x_train_pos, x_train_neg))\n",
        "y_np_train = np.concatenate((y_train_pos, y_train_neg))\n",
        "x_np_test = np.concatenate((x_test_pos, x_test_neg))\n",
        "y_np_test = np.concatenate((y_test_pos, y_test_neg))\n",
        "x_train_t = torch.Tensor(x_np_train)\n",
        "y_train_t = torch.Tensor(y_np_train)\n",
        "x_test_t = torch.Tensor(x_np_test)\n",
        "y_test_t = torch.Tensor(y_np_test)\n",
        "train_data = data.TensorDataset(x_train_t, y_train_t)\n",
        "test_data = data.TensorDataset(x_test_t, y_test_t)\n",
        "train_dataloader = data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "lr = 0.0001\n",
        "beta_1 = 0.9\n",
        "beta_2 = 0.99\n",
        "net = G4Detector(5)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
        "\n",
        "\n",
        "def accuracy(output, target):\n",
        "    \"\"\"Computes the accuracy for multiple binary predictions\"\"\"\n",
        "    pred = output >= 0.5\n",
        "    truth = target >= 0.5\n",
        "    acc = pred.eq(truth).sum().item() / target.numel()\n",
        "    return acc\n",
        "\n",
        "\n",
        "epoches = 15\n",
        "stat_every_batch = 10\n",
        "use_cuda = True\n",
        "for epoch in range(epoches):\n",
        "    running_loss = 0.\n",
        "    running_acc = 0.\n",
        "    for (i, data) in enumerate(train_dataloader, 0):\n",
        "        (inputs, labels) = data\n",
        "    optimizer.zero_grad()\n",
        "    if use_cuda:\n",
        "        inputs.cuda()\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    running_acc += accuracy(outputs, labels)\n",
        "\n",
        "    if i % stat_every_batch == stat_every_batch - 1:  # print every 2000 minibatches\n",
        "        print('[%d, %5d] loss: %.3f acc: %.3f' % epoch + 1, i + 1,\n",
        "              running_loss / stat_every_batch, running_acc\n",
        "              / stat_every_batch)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "\n",
        "for (i, data) in enumerate(test_dataloader, 0):\n",
        "    (inputs, labels) = data\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    running_loss += loss.item()\n",
        "    running_acc += accuracy(outputs, labels)\n",
        "    print('Test_loss: %.3f Test_acc: %.3f' % (running_loss / (i + 1),\n",
        "                                              running_acc / (i + 1)))\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "all_labels = None\n",
        "all_outputs = None\n",
        "for (i, data) in enumerate(test_dataloader, 0):\n",
        "    (inputs, labels) = data\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    running_loss += loss.item()\n",
        "    running_acc += accuracy(outputs, labels)\n",
        "    if all_labels is None:\n",
        "        all_labels = labels.numpy()\n",
        "    else:\n",
        "        all_labels = np.concatenate((all_labels, labels.numpy()))\n",
        "    if all_outputs is None:\n",
        "        all_outputs = outputs.detach().numpy()\n",
        "    else:\n",
        "        all_outputs = np.concatenate((all_outputs,\n",
        "                                      outputs.detach().numpy()))\n",
        "print('Test loss: %.3f acc: %.3f' % (running_loss / (i + 1),\n",
        "                                     running_acc / (i + 1)))\n",
        "(fpr, tpr, threshold) = metrics.roc_curve(all_labels, all_outputs)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label='AUC = %0.5f' % roc_auc)\n",
        "plt.legend(loc='lower right')\n",
        "plt.plot([0, 1], [0, 1], 'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OFyumqOjLU05"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}